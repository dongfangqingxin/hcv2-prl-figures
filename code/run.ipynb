{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d5a52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[simple full uncrelated] Chi2/ndf for D0 vs model tamu_d0_rebin: 0.5698\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.5700\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.5698\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.5805\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.5565\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.4391\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.5631\n",
      "6_Reso_Only               | chi2/ndf = 0.8403\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model catania_d0_rebin: 13.8072\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 13.4596\n",
      "1_All_Uncorrelated        | chi2/ndf = 13.8072\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 18.3620\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 12.5592\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 11.9418\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 12.9926\n",
      "6_Reso_Only               | chi2/ndf = 18.7270\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model langevin_d0_rebin: 298.1132\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 269.9736\n",
      "1_All_Uncorrelated        | chi2/ndf = 298.1132\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 304.6163\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 245.6686\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 184.5763\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 257.2410\n",
      "6_Reso_Only               | chi2/ndf = 376.5604\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model htl_d0_rebin: 255.3028\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 233.3112\n",
      "1_All_Uncorrelated        | chi2/ndf = 255.3028\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 284.6967\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 211.9809\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 163.3668\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 222.1240\n",
      "6_Reso_Only               | chi2/ndf = 328.5777\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model latQCD_d0_rebin: 151.8252\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 146.2884\n",
      "1_All_Uncorrelated        | chi2/ndf = 151.8252\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 231.8917\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 132.6109\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 129.7188\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 139.1019\n",
      "6_Reso_Only               | chi2/ndf = 247.4800\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model lbt_d0_rebin: 117.2525\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 117.7457\n",
      "1_All_Uncorrelated        | chi2/ndf = 117.2525\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 171.1039\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 107.2262\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 106.6470\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 112.2337\n",
      "6_Reso_Only               | chi2/ndf = 172.5547\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for D0 vs model epos4hq_d0_rebin: 31.7352\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 31.6039\n",
      "1_All_Uncorrelated        | chi2/ndf = 31.7352\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 51.4667\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 28.8380\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 28.6923\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 30.1565\n",
      "6_Reso_Only               | chi2/ndf = 52.0685\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model tamu_lc_rebin: 0.2631\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.2630\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.2631\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.2125\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.2468\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.1659\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.2546\n",
      "6_Reso_Only               | chi2/ndf = 0.3442\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model catania_lc_rebin: 0.2361\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.2361\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.2361\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.2757\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.2220\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.1995\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.2288\n",
      "6_Reso_Only               | chi2/ndf = 0.3024\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model langevin_lc_rebin: 0.0770\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.0770\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.0770\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.1145\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.0725\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.0707\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.0747\n",
      "6_Reso_Only               | chi2/ndf = 0.1163\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model htl_lc_rebin: 0.9008\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.9005\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.9008\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.5515\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.8498\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.4373\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.8743\n",
      "6_Reso_Only               | chi2/ndf = 1.2863\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model latQCD_lc_rebin: 2.0669\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 2.0670\n",
      "1_All_Uncorrelated        | chi2/ndf = 2.0670\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 2.5483\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 1.9397\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 1.6941\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 2.0012\n",
      "6_Reso_Only               | chi2/ndf = 3.1184\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model lbt_lc_rebin: 0.5885\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.5883\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.5885\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 0.4716\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.5557\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.3387\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.5715\n",
      "6_Reso_Only               | chi2/ndf = 0.9138\n",
      "======================================================================\n",
      "[simple full uncrelated] Chi2/ndf for lc vs model epos4hq_lc_rebin: 0.9577\n",
      "\n",
      "======================================================================\n",
      "SYSTEMATIC ERROR CORRELATION TEST RESULTS SUMMARY\n",
      "======================================================================\n",
      "0_Baseline                | chi2/ndf = 0.9578\n",
      "1_All_Uncorrelated        | chi2/ndf = 0.9578\n",
      "2_Supplement1_All_Interbin_Corr | chi2/ndf = 1.3099\n",
      "3_Supplement2_Intrabin_Corr | chi2/ndf = 0.8932\n",
      "4_Supplement3_Full_Corr   | chi2/ndf = 0.8650\n",
      "5_Partial_Intrabin_Corr   | chi2/ndf = 0.9243\n",
      "6_Reso_Only               | chi2/ndf = 1.3957\n",
      "======================================================================\n",
      "use source data in ../input-models/arxivv1905.09216-tamu/lc-up.dat\n",
      "use source data in ../input-models/arxivv1905.09216-tamu/lc-low.dat\n",
      "use source data in ../input-models/arxivv1905.09216-tamu/d0-up.dat\n",
      "use source data in ../input-models/arxivv1905.09216-tamu/d0-low.dat\n",
      "use source data in ../input-models/Fwd_ Predictions for LambdaC elliptic flow/v2_D0_502_3050_Catania_band.dat\n",
      "use source data in ../input-models/Fwd_ Predictions for LambdaC elliptic flow/v2_Lc_502_3050_Catania_band.dat\n",
      "use source data in ../input-models/langevin-d4-results-to-pxy25.3.22/Lcv2fnwsnlo30-50.dat\n",
      "use source data in ../input-models/langevin-d4-results-to-pxy25.3.22/D0v2fnwsnlo30-50.dat\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TROOT::Append>: Replacing existing TH1: d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: tamu_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: tamu_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: catania_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: catania_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: langevin_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: langevin_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: htl_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: htl_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: latQCD_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: latQCD_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: lbt_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: lbt_d0 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: epos4hq_lc (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: epos4hq_d0 (Potential memory leak).\n",
      "Info in <TCanvas::Print>: pdf file ../output/compare-model.pdf has been created\n"
     ]
    }
   ],
   "source": [
    "%run plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a251ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=reso CORR, fit & frac UNC, Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: reso CORR, fit & frac UNC, Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=reso CORR, fit & frac UNC, Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: reso CORR, fit & frac UNC, Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=ignoring reso, fit & frac UNC, Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: ignoring reso, fit & frac UNC, Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=ignoring reso, fit & frac UNC, Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: ignoring reso, fit & frac UNC, Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=Everything UNC., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: Everything UNC., Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=Everything UNC., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: Everything UNC., Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=Everything CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: Everything CORR., Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=Everything CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: Everything CORR., Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=only fit and reso CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: only fit and reso CORR., Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=only fit and reso CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: only fit and reso CORR., Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=only fraction and reso as CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: only fraction and reso as CORR., Combine non-strange: True\n",
      "Comparison: Lambda_c vs (D0+D+)\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=lc, Method=binBybin-difference, Case=only fraction and reso as CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: lc, Correlation case: only fraction and reso as CORR., Combine non-strange: False\n",
      "Comparison: Lambda_c vs D0\n",
      "Lambda_c bins: [4, 5, 6, 8, 12, 24]\n",
      "Reference particle bins: [4, 5, 6, 7, 8, 10, 12, 16, 24]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [4, 5, 6, 7, 8, 10, 12, 16, 24] -> target bins [4, 5, 6, 8, 12, 24]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=reso CORR, fit & frac UNC, Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: reso CORR, fit & frac UNC, Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=reso CORR, fit & frac UNC, Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: reso CORR, fit & frac UNC, Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=ignoring reso, fit & frac UNC, Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: ignoring reso, fit & frac UNC, Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=ignoring reso, fit & frac UNC, Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: ignoring reso, fit & frac UNC, Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=Everything UNC., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: Everything UNC., Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=Everything UNC., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: Everything UNC., Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=Everything CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: Everything CORR., Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=Everything CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: Everything CORR., Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=only fit and reso CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: only fit and reso CORR., Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=only fit and reso CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: only fit and reso CORR., Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=only fraction and reso as CORR., Combine non-strange=True =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: only fraction and reso as CORR., Combine non-strange: True\n",
      "Comparison: Ds vs (D0+D+)\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "===== Test combination: Particle=ds, Method=binBybin-difference, Case=only fraction and reso as CORR., Combine non-strange=False =====\n",
      "Method: binBybin-difference, Particle: ds, Correlation case: only fraction and reso as CORR., Combine non-strange: False\n",
      "Comparison: Ds vs D0\n",
      "Ds bins: [1, 2, 3, 4, 5]\n",
      "Reference particle bins: [1, 1.5, 2, 2.5, 3, 3.5, 4, 5]\n",
      "Original bins match target bins, no rebinning needed\n",
      "Rebinning completed: original bins [1, 1.5, 2, 2.5, 3, 3.5, 4, 5] -> target bins [1, 2, 3, 4, 5]\n",
      "Test result: Success\n",
      "\n",
      "================================================================================\n",
      "Summary of all test cases\n",
      "================================================================================\n",
      "\n",
      "----- Particle: lc -----\n",
      "  Method: binBybin-difference\n",
      "    Correlation case: reso CORR, fit & frac UNC\n",
      "      Combine non-strange: Array: [0.90566301 2.39642729 2.37419664 1.61049886 1.42990591], Total Nsigma: 5.3112321817648445\n",
      "      Do not combine non-strange: Array: [0.9237669  2.49582886 2.40493334 1.60199525 1.60234451], Total Nsigma: 5.438301831888318\n",
      "    Correlation case: ignoring reso, fit & frac UNC\n",
      "      Combine non-strange: Array: [0.90595521 2.39689632 2.37904513 1.62158271 1.42777133], Total Nsigma: 5.3173193452240985\n",
      "      Do not combine non-strange: Array: [0.92397007 2.49635903 2.4053934  1.60205091 1.60239895], Total Nsigma: 5.438885290387002\n",
      "    Correlation case: Everything UNC.\n",
      "      Combine non-strange: Array: [0.90573339 2.39660417 2.37434648 1.61053365 1.42992318], Total Nsigma: 5.311431468143727\n",
      "      Do not combine non-strange: Array: [0.92386768 2.49607835 2.40514499 1.60204431 1.60236689], Total Nsigma: 5.438582466008896\n",
      "    Correlation case: Everything CORR.\n",
      "      Combine non-strange: Array: [0.8677821  2.27146458 2.14302995 1.47736137 1.3176886 ], Total Nsigma: 5.038828917373176\n",
      "      Do not combine non-strange: Array: [0.89515953 2.34042751 2.21215924 1.48314858 1.42958486], Total Nsigma: 5.154886986078862\n",
      "    Correlation case: only fit and reso CORR.\n",
      "      Combine non-strange: Array: [0.86885609 2.27441101 2.14602982 1.47861241 1.32027729], Total Nsigma: 5.043376654541953\n",
      "      Do not combine non-strange: Array: [0.89538517 2.34101358 2.212803   1.48340231 1.43007763], Total Nsigma: 5.155816184049316\n",
      "    Correlation case: only fraction and reso as CORR.\n",
      "      Combine non-strange: Array: [0.90444686 2.3929815  2.3701365  1.60888268 1.42661901], Total Nsigma: 5.305470116835841\n",
      "      Do not combine non-strange: Array: [0.92351912 2.4951187  2.40410698 1.60167568 1.60165144], Total Nsigma: 5.437111853931845\n",
      "\n",
      "----- Particle: ds -----\n",
      "  Method: binBybin-difference\n",
      "    Correlation case: reso CORR, fit & frac UNC\n",
      "      Combine non-strange: Array: [1.17958505 1.61003475 2.11304464 0.32921329], Total Nsigma: 3.938269433841963\n",
      "      Do not combine non-strange: Array: [1.1965739  1.63222436 2.10717455 0.28721797], Total Nsigma: 3.9423847047569076\n",
      "    Correlation case: ignoring reso, fit & frac UNC\n",
      "      Combine non-strange: Array: [1.10098394 1.50581407 2.11189421 0.32913193], Total Nsigma: 3.8561590012178573\n",
      "      Do not combine non-strange: Array: [1.19805018 1.63756076 2.11022202 0.28756095], Total Nsigma: 3.947492552642243\n",
      "    Correlation case: Everything UNC.\n",
      "      Combine non-strange: Array: [1.17960243 1.61057048 2.11403378 0.32935147], Total Nsigma: 3.9391588045533394\n",
      "      Do not combine non-strange: Array: [1.19659909 1.63301059 2.10859939 0.28738928], Total Nsigma: 3.943665715245288\n",
      "    Correlation case: Everything CORR.\n",
      "      Combine non-strange: Array: [1.15775737 1.46239354 1.83557164 0.28733274], Total Nsigma: 3.685883738836613\n",
      "      Do not combine non-strange: Array: [1.18542091 1.57108535 1.99167002 0.26186948], Total Nsigma: 3.8339589810992116\n",
      "    Correlation case: only fit and reso CORR.\n",
      "      Combine non-strange: Array: [1.16436894 1.50295486 1.88177665 0.29403437], Total Nsigma: 3.736384630245721\n",
      "      Do not combine non-strange: Array: [1.18679094 1.58079916 2.00357378 0.26317873], Total Nsigma: 3.846541601101755\n",
      "    Correlation case: only fraction and reso as CORR.\n",
      "      Combine non-strange: Array: [1.17271241 1.56046484 2.04824158 0.31988718], Total Nsigma: 3.870773225625228\n",
      "      Do not combine non-strange: Array: [1.19516975 1.62153787 2.09334015 0.2855186 ], Total Nsigma: 3.927978035389983\n",
      "\n",
      "================================================================================\n",
      "Testing completed\n"
     ]
    }
   ],
   "source": [
    "%run '../Nsigma/nsigma.py'\n",
    "# !root -x -q 'TestNsigma.C'\n",
    "# !root -x -q 'significance_DoubleRatioLcD0.C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ad4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功打开输入文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst.root\n",
      "加载对象 reso_syst，数据点数量: 7\n",
      "加载对象 fit_syst，数据点数量: 7\n",
      "加载对象 fd_syst，数据点数量: 7\n",
      "加载对象 tot_syst，数据点数量: 7\n",
      "\n",
      "开始修改reso_syst的y误差（设置为y值的0.2%）...\n",
      "  点0: x=2.5, y=0.1284, 新y误差=0.000257\n",
      "  点2: x=4.5, y=0.1907, 新y误差=0.000381\n",
      "  点4: x=7.0, y=0.1786, 新y误差=0.000357\n",
      "  点6: x=18.0, y=0.1488, 新y误差=0.000298\n",
      "\n",
      "开始重新计算tot_syst...\n",
      "找到7个共同的x值: [2.5, 3.5, 4.5, 5.5, 7.0, 10.0, 18.0]\n",
      "  x=2.5: fit_err=0.025000, reso_err=0.000257, fd_err=0.003654 → tot_err=0.025267\n",
      "  x=3.5: fit_err=0.018000, reso_err=0.000335, fd_err=0.003405 → tot_err=0.018322\n",
      "  x=4.5: fit_err=0.018000, reso_err=0.000381, fd_err=0.001500 → tot_err=0.018066\n",
      "  x=5.5: fit_err=0.018000, reso_err=0.000416, fd_err=0.001500 → tot_err=0.018067\n",
      "  x=7.0: fit_err=0.018000, reso_err=0.000357, fd_err=0.001500 → tot_err=0.018066\n",
      "  x=10.0: fit_err=0.025000, reso_err=0.000285, fd_err=0.001500 → tot_err=0.025047\n",
      "  x=18.0: fit_err=0.025000, reso_err=0.000298, fd_err=0.003977 → tot_err=0.025316\n",
      "\n",
      "成功创建输出文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root\n",
      "\n",
      "处理完成！输出文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root\n",
      "修改内容：\n",
      "  1. reso_syst: 所有点y误差设为y值的0.2%\n",
      "  2. tot_syst: 重新计算为 sqrt(fit_syst² + reso_syst² + fd_syst²)\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import sys\n",
    "\n",
    "def adjust_reso_syst_and_recalc_tot(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    处理ROOT文件：\n",
    "    1. 将reso_syst所有数据点的y误差设置为中心值（y值）的0.2%\n",
    "    2. 重新计算tot_syst（总系统误差）：tot_syst = sqrt(fit_syst² + reso_syst² + fd_syst²)\n",
    "    3. 保存修改后的数据到新文件\n",
    "    \n",
    "    参数:\n",
    "        input_file_path: 输入ROOT文件路径（包含reso_syst/fit_syst/fd_syst/tot_syst等对象）\n",
    "        output_file_path: 输出ROOT文件路径（保存修改后的数据）\n",
    "    \"\"\"\n",
    "    # 初始化ROOT批处理模式（无GUI）\n",
    "    ROOT.gROOT.SetBatch(True)\n",
    "    \n",
    "    # 1. 打开输入文件\n",
    "    try:\n",
    "        in_file = ROOT.TFile.Open(input_file_path, \"READ\")\n",
    "        if not in_file or in_file.IsZombie():\n",
    "            raise RuntimeError(f\"无法打开输入文件: {input_file_path}\")\n",
    "        print(f\"成功打开输入文件: {input_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"打开文件失败: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 2. 检查必要对象是否存在\n",
    "    required_objs = [\"reso_syst\", \"fit_syst\", \"fd_syst\", \"tot_syst\"]\n",
    "    obj_dict = {}\n",
    "    for obj_name in required_objs:\n",
    "        obj = in_file.Get(obj_name)\n",
    "        if not obj or not isinstance(obj, ROOT.TGraphAsymmErrors):\n",
    "            print(f\"错误：输入文件中未找到有效对象 {obj_name} (TGraphAsymmErrors类型)\")\n",
    "            in_file.Close()\n",
    "            sys.exit(1)\n",
    "        obj_dict[obj_name] = obj\n",
    "        print(f\"加载对象 {obj_name}，数据点数量: {obj.GetN()}\")\n",
    "    \n",
    "    # 3. 处理reso_syst：设置y误差为中心值的0.2%\n",
    "    reso_graph = obj_dict[\"reso_syst\"]\n",
    "    n_points = reso_graph.GetN()\n",
    "    print(f\"\\n开始修改reso_syst的y误差（设置为y值的0.2%）...\")\n",
    "    \n",
    "    # 创建修改后的reso_syst副本（避免修改原文件数据）\n",
    "    new_reso_graph = ROOT.TGraphAsymmErrors()\n",
    "    new_reso_graph.SetName(\"reso_syst\")\n",
    "    new_reso_graph.SetTitle(\"reso_syst (y error = 0.2% of y value)\")\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        # 获取原始x/y值和x误差（x误差保持不变）\n",
    "        x = reso_graph.GetX()[i]\n",
    "        y = reso_graph.GetY()[i]\n",
    "        x_err_low = reso_graph.GetEXlow()[i]\n",
    "        x_err_high = reso_graph.GetEXhigh()[i]\n",
    "        \n",
    "        # 计算新的y误差：0.2% of y值（上下误差相同）\n",
    "        y_err = abs(y) * 0.002  # 0.2% = 0.002\n",
    "        y_err_low = y_err\n",
    "        y_err_high = y_err\n",
    "        \n",
    "        # 设置新数据点和误差\n",
    "        new_reso_graph.SetPoint(i, x, y)\n",
    "        new_reso_graph.SetPointError(i, x_err_low, x_err_high, y_err_low, y_err_high)\n",
    "        \n",
    "        if i % 2 == 0:  # 每2个点打印一次进度\n",
    "            print(f\"  点{i}: x={x:.1f}, y={y:.4f}, 新y误差={y_err:.6f}\")\n",
    "    \n",
    "    # 4. 重新计算tot_syst：总误差 = sqrt(fit² + reso² + fd²)\n",
    "    print(f\"\\n开始重新计算tot_syst...\")\n",
    "    fit_graph = obj_dict[\"fit_syst\"]\n",
    "    fd_graph = obj_dict[\"fd_syst\"]\n",
    "    tot_graph = obj_dict[\"tot_syst\"]\n",
    "    \n",
    "    # 检查各图数据点数量是否匹配（按x值匹配，而非索引）\n",
    "    # 第一步：构建x值到数据的映射\n",
    "    def build_x_map(graph):\n",
    "        \"\"\"构建x值到(索引, y, y_err_low, y_err_high)的映射\"\"\"\n",
    "        x_map = {}\n",
    "        n = graph.GetN()\n",
    "        for i in range(n):\n",
    "            x = graph.GetX()[i]\n",
    "            y = graph.GetY()[i]\n",
    "            y_err_low = graph.GetEYlow()[i]\n",
    "            y_err_high = graph.GetEYhigh()[i]\n",
    "            x_map[round(x, 1)] = (i, y, y_err_low, y_err_high)  # 四舍五入避免浮点误差\n",
    "        return x_map\n",
    "    \n",
    "    # 构建各图的x值映射\n",
    "    reso_x_map = build_x_map(new_reso_graph)\n",
    "    fit_x_map = build_x_map(fit_graph)\n",
    "    fd_x_map = build_x_map(fd_graph)\n",
    "    \n",
    "    # 收集所有有效x值（取交集）\n",
    "    common_x = set(reso_x_map.keys()) & set(fit_x_map.keys()) & set(fd_x_map.keys())\n",
    "    if not common_x:\n",
    "        print(\"错误：reso_syst/fit_syst/fd_syst无共同的x值，无法计算tot_syst\")\n",
    "        in_file.Close()\n",
    "        sys.exit(1)\n",
    "    common_x = sorted(list(common_x))\n",
    "    print(f\"找到{len(common_x)}个共同的x值: {common_x}\")\n",
    "    \n",
    "    # 创建新的tot_syst图\n",
    "    new_tot_graph = ROOT.TGraphAsymmErrors()\n",
    "    new_tot_graph.SetName(\"tot_syst\")\n",
    "    new_tot_graph.SetTitle(\"tot_syst (recalculated: sqrt(fit² + reso² + fd²))\")\n",
    "    \n",
    "    for idx, x in enumerate(common_x):\n",
    "        # 获取各系统误差的y误差（使用上误差，通常上下误差对称）\n",
    "        _, _, fit_err, _ = fit_x_map[x]\n",
    "        _, _, reso_err, _ = reso_x_map[x]\n",
    "        _, _, fd_err, _ = fd_x_map[x]\n",
    "        \n",
    "        # 总误差 = 平方和开根号\n",
    "        tot_err = (fit_err**2 + reso_err**2 + fd_err**2)**0.5\n",
    "        \n",
    "        # 获取x误差（从任意一个图取，假设x误差一致）\n",
    "        reso_idx, _, _, _ = reso_x_map[x]\n",
    "        x_err_low = new_reso_graph.GetEXlow()[reso_idx]\n",
    "        x_err_high = new_reso_graph.GetEXhigh()[reso_idx]\n",
    "        \n",
    "        # tot_syst的y值保持与原tot_syst一致（或设为0，根据需求调整）\n",
    "        if round(x,1) in build_x_map(tot_graph):\n",
    "            tot_idx, tot_y, _, _ = build_x_map(tot_graph)[round(x,1)]\n",
    "        else:\n",
    "            tot_y = 0.0\n",
    "        \n",
    "        # 设置新tot_syst的数据点\n",
    "        new_tot_graph.SetPoint(idx, x, tot_y)\n",
    "        new_tot_graph.SetPointError(idx, x_err_low, x_err_high, tot_err, tot_err)\n",
    "        \n",
    "        print(f\"  x={x:.1f}: fit_err={fit_err:.6f}, reso_err={reso_err:.6f}, fd_err={fd_err:.6f} → tot_err={tot_err:.6f}\")\n",
    "    \n",
    "    # 5. 保存修改后的数据到输出文件\n",
    "    try:\n",
    "        out_file = ROOT.TFile.Open(output_file_path, \"RECREATE\")\n",
    "        if not out_file or out_file.IsZombie():\n",
    "            raise RuntimeError(f\"无法创建输出文件: {output_file_path}\")\n",
    "        print(f\"\\n成功创建输出文件: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"创建输出文件失败: {e}\")\n",
    "        in_file.Close()\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 写入所有对象（保留原对象，替换修改后的reso_syst和tot_syst）\n",
    "    out_file.cd()\n",
    "    # 写入修改后的reso_syst\n",
    "    new_reso_graph.Write()\n",
    "    # 写入重新计算的tot_syst\n",
    "    new_tot_graph.Write()\n",
    "    # 写入其他未修改的对象\n",
    "    obj_dict[\"fit_syst\"].Write()\n",
    "    obj_dict[\"fd_syst\"].Write()\n",
    "    # 如果有gvn_prompt_stat也一并写入\n",
    "    gvn_stat = in_file.Get(\"gvn_prompt_stat\")\n",
    "    if gvn_stat:\n",
    "        gvn_stat.Write()\n",
    "    \n",
    "    # 6. 关闭文件\n",
    "    in_file.Close()\n",
    "    out_file.Close()\n",
    "    \n",
    "    print(f\"\\n处理完成！输出文件: {output_file_path}\")\n",
    "    print(\"修改内容：\")\n",
    "    print(\"  1. reso_syst: 所有点y误差设为y值的0.2%\")\n",
    "    print(\"  2. tot_syst: 重新计算为 sqrt(fit_syst² + reso_syst² + fd_syst²)\")\n",
    "\n",
    "def main():\n",
    "    # if len(sys.argv) != 3:\n",
    "    #     print(\"用法: python adjust_syst.py <输入文件路径> <输出文件路径>\")\n",
    "    #     print(\"示例: python adjust_syst.py merged.root f1.root\")\n",
    "    #     sys.exit(1)\n",
    "    \n",
    "    input_path = '/home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst.root'\n",
    "    output_path = '/home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root'\n",
    "    adjust_reso_syst_and_recalc_tot(input_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca217e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功打开输入文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst.root\n",
      "加载对象 reso_syst，数据点数量: 7\n",
      "加载对象 fit_syst，数据点数量: 7\n",
      "加载对象 fd_syst，数据点数量: 7\n",
      "加载对象 tot_syst，数据点数量: 7\n",
      "\n",
      "开始修改reso_syst的y误差（设置为y值的0.2%）...\n",
      "  点0: x=2.5, y=0.1284, 新y误差(下/上)=0.000257/0.000257\n",
      "  点2: x=4.5, y=0.1907, 新y误差(下/上)=0.000381/0.000381\n",
      "  点4: x=7.0, y=0.1786, 新y误差(下/上)=0.000357/0.000357\n",
      "  点6: x=18.0, y=0.1488, 新y误差(下/上)=0.000298/0.000298\n",
      "\n",
      "找到7个共同的x值: [2.5, 3.5, 4.5, 5.5, 7.0, 10.0, 18.0]\n",
      "\n",
      "开始重新计算tot_syst（非对称误差）...\n",
      "  x=2.5: \n",
      "    fit误差(下/上)=0.025000/0.025000\n",
      "    reso误差(下/上)=0.000257/0.000257\n",
      "    fd误差(下/上)=0.003654/0.005396\n",
      "    → tot误差(下/上)=0.025267/0.025577\n",
      "  x=3.5: \n",
      "    fit误差(下/上)=0.018000/0.018000\n",
      "    reso误差(下/上)=0.000335/0.000335\n",
      "    fd误差(下/上)=0.003405/0.004530\n",
      "    → tot误差(下/上)=0.018322/0.018564\n",
      "  x=4.5: \n",
      "    fit误差(下/上)=0.018000/0.018000\n",
      "    reso误差(下/上)=0.000381/0.000381\n",
      "    fd误差(下/上)=0.001500/0.001500\n",
      "    → tot误差(下/上)=0.018066/0.018066\n",
      "  x=5.5: \n",
      "    fit误差(下/上)=0.018000/0.018000\n",
      "    reso误差(下/上)=0.000416/0.000416\n",
      "    fd误差(下/上)=0.001500/0.001500\n",
      "    → tot误差(下/上)=0.018067/0.018067\n",
      "  x=7.0: \n",
      "    fit误差(下/上)=0.018000/0.018000\n",
      "    reso误差(下/上)=0.000357/0.000357\n",
      "    fd误差(下/上)=0.001500/0.001500\n",
      "    → tot误差(下/上)=0.018066/0.018066\n",
      "  x=10.0: \n",
      "    fit误差(下/上)=0.025000/0.025000\n",
      "    reso误差(下/上)=0.000285/0.000285\n",
      "    fd误差(下/上)=0.001500/0.001500\n",
      "    → tot误差(下/上)=0.025047/0.025047\n",
      "  x=18.0: \n",
      "    fit误差(下/上)=0.025000/0.025000\n",
      "    reso误差(下/上)=0.000298/0.000298\n",
      "    fd误差(下/上)=0.003977/0.005964\n",
      "    → tot误差(下/上)=0.025316/0.025703\n",
      "\n",
      "成功创建输出文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root\n",
      "\n",
      "处理完成！输出文件: /home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root\n",
      "修改内容：\n",
      "  1. reso_syst: 所有点y误差设为y值的0.2%（对称）\n",
      "  2. tot_syst: 重新计算非对称误差：\n",
      "     - 下误差 = √(fit_err_low² + reso_err_low² + fd_err_low²)\n",
      "     - 上误差 = √(fit_err_high² + reso_err_high² + fd_err_high²)\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import sys\n",
    "import math\n",
    "\n",
    "def adjust_reso_syst_and_recalc_tot(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    处理ROOT文件：\n",
    "    1. 将reso_syst所有数据点的y误差设置为中心值（y值）的0.2%\n",
    "    2. 重新计算tot_syst（总系统误差）：\n",
    "       - 下误差：tot_err_low = sqrt(fit_err_low² + reso_err_low² + fd_err_low²)\n",
    "       - 上误差：tot_err_high = sqrt(fit_err_high² + reso_err_high² + fd_err_high²)\n",
    "    3. 保存修改后的数据到新文件\n",
    "    \n",
    "    参数:\n",
    "        input_file_path: 输入ROOT文件路径（包含reso_syst/fit_syst/fd_syst/tot_syst等对象）\n",
    "        output_file_path: 输出ROOT文件路径（保存修改后的数据）\n",
    "    \"\"\"\n",
    "    # 初始化ROOT批处理模式（无GUI）\n",
    "    ROOT.gROOT.SetBatch(True)\n",
    "    \n",
    "    # 1. 打开输入文件\n",
    "    try:\n",
    "        in_file = ROOT.TFile.Open(input_file_path, \"READ\")\n",
    "        if not in_file or in_file.IsZombie():\n",
    "            raise RuntimeError(f\"无法打开输入文件: {input_file_path}\")\n",
    "        print(f\"成功打开输入文件: {input_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"打开文件失败: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 2. 检查必要对象是否存在\n",
    "    required_objs = [\"reso_syst\", \"fit_syst\", \"fd_syst\", \"tot_syst\"]\n",
    "    obj_dict = {}\n",
    "    for obj_name in required_objs:\n",
    "        obj = in_file.Get(obj_name)\n",
    "        if not obj or not isinstance(obj, ROOT.TGraphAsymmErrors):\n",
    "            print(f\"错误：输入文件中未找到有效对象 {obj_name} (TGraphAsymmErrors类型)\")\n",
    "            in_file.Close()\n",
    "            sys.exit(1)\n",
    "        obj_dict[obj_name] = obj\n",
    "        print(f\"加载对象 {obj_name}，数据点数量: {obj.GetN()}\")\n",
    "    \n",
    "    # 3. 处理reso_syst：设置y误差为中心值的0.2%（非对称误差也设为对称的0.2%）\n",
    "    reso_graph = obj_dict[\"reso_syst\"]\n",
    "    n_points = reso_graph.GetN()\n",
    "    print(f\"\\n开始修改reso_syst的y误差（设置为y值的0.2%）...\")\n",
    "    \n",
    "    # 创建修改后的reso_syst副本（避免修改原文件数据）\n",
    "    new_reso_graph = ROOT.TGraphAsymmErrors()\n",
    "    new_reso_graph.SetName(\"reso_syst\")\n",
    "    new_reso_graph.SetTitle(\"reso_syst (y error = 0.2% of y value)\")\n",
    "    \n",
    "    reso_x_map = {}  # 存储x值到(索引, y, x_err_low, x_err_high, y_err_low, y_err_high)的映射\n",
    "    for i in range(n_points):\n",
    "        # 获取原始x/y值和x误差（x误差保持不变）\n",
    "        x = reso_graph.GetX()[i]\n",
    "        y = reso_graph.GetY()[i]\n",
    "        x_err_low = reso_graph.GetEXlow()[i]\n",
    "        x_err_high = reso_graph.GetEXhigh()[i]\n",
    "        \n",
    "        # 计算新的y误差：0.2% of y值（上下误差相同）\n",
    "        y_err = abs(y) * 0.002  # 0.2% = 0.002\n",
    "        y_err_low = y_err\n",
    "        y_err_high = y_err\n",
    "        \n",
    "        # 设置新数据点和误差\n",
    "        new_reso_graph.SetPoint(i, x, y)\n",
    "        new_reso_graph.SetPointError(i, x_err_low, x_err_high, y_err_low, y_err_high)\n",
    "        \n",
    "        # 存入映射表（四舍五入避免浮点误差）\n",
    "        reso_x_map[round(x, 3)] = (i, y, x_err_low, x_err_high, y_err_low, y_err_high)\n",
    "        \n",
    "        if i % 2 == 0:  # 每2个点打印一次进度\n",
    "            print(f\"  点{i}: x={x:.1f}, y={y:.4f}, 新y误差(下/上)={y_err_low:.6f}/{y_err_high:.6f}\")\n",
    "    \n",
    "    # 4. 构建其他系统误差的x值映射（保留非对称误差）\n",
    "    def build_asymm_x_map(graph):\n",
    "        \"\"\"构建x值到(索引, y, x_err_low, x_err_high, y_err_low, y_err_high)的映射\"\"\"\n",
    "        x_map = {}\n",
    "        n = graph.GetN()\n",
    "        for i in range(n):\n",
    "            x = graph.GetX()[i]\n",
    "            y = graph.GetY()[i]\n",
    "            x_err_low = graph.GetEXlow()[i]\n",
    "            x_err_high = graph.GetEXhigh()[i]\n",
    "            y_err_low = graph.GetEYlow()[i]\n",
    "            y_err_high = graph.GetEYhigh()[i]\n",
    "            x_map[round(x, 3)] = (i, y, x_err_low, x_err_high, y_err_low, y_err_high)\n",
    "        return x_map\n",
    "    \n",
    "    fit_x_map = build_asymm_x_map(obj_dict[\"fit_syst\"])\n",
    "    fd_x_map = build_asymm_x_map(obj_dict[\"fd_syst\"])\n",
    "    tot_x_map = build_asymm_x_map(obj_dict[\"tot_syst\"])\n",
    "    \n",
    "    # 收集所有有效x值（取交集）\n",
    "    common_x = set(reso_x_map.keys()) & set(fit_x_map.keys()) & set(fd_x_map.keys())\n",
    "    if not common_x:\n",
    "        print(\"错误：reso_syst/fit_syst/fd_syst无共同的x值，无法计算tot_syst\")\n",
    "        in_file.Close()\n",
    "        sys.exit(1)\n",
    "    common_x = sorted(list(common_x))\n",
    "    print(f\"\\n找到{len(common_x)}个共同的x值: {[round(x,1) for x in common_x]}\")\n",
    "    \n",
    "    # 5. 重新计算tot_syst（非对称误差）\n",
    "    print(f\"\\n开始重新计算tot_syst（非对称误差）...\")\n",
    "    new_tot_graph = ROOT.TGraphAsymmErrors()\n",
    "    new_tot_graph.SetName(\"tot_syst\")\n",
    "    new_tot_graph.SetTitle(\"tot_syst (recalculated: sqrt(fit² + reso² + fd²) 非对称误差)\")\n",
    "    \n",
    "    for idx, x_key in enumerate(common_x):\n",
    "        x = float(x_key)\n",
    "        \n",
    "        # 获取各系统误差的非对称y误差\n",
    "        # reso_syst（已修改）\n",
    "        _, reso_y, reso_xl, reso_xh, reso_yl, reso_yh = reso_x_map[x_key]\n",
    "        # fit_syst（原始非对称误差）\n",
    "        _, fit_y, fit_xl, fit_xh, fit_yl, fit_yh = fit_x_map[x_key]\n",
    "        # fd_syst（原始非对称误差）\n",
    "        _, fd_y, fd_xl, fd_xh, fd_yl, fd_yh = fd_x_map[x_key]\n",
    "        \n",
    "        # 核心：非对称总误差计算（平方和开根号）\n",
    "        # 下误差：tot_err_low = sqrt(fit_err_low² + reso_err_low² + fd_err_low²)\n",
    "        tot_err_low = math.sqrt(fit_yl**2 + reso_yl**2 + fd_yl**2)\n",
    "        # 上误差：tot_err_high = sqrt(fit_err_high² + reso_err_high² + fd_err_high²)\n",
    "        tot_err_high = math.sqrt(fit_yh**2 + reso_yh**2 + fd_yh**2)\n",
    "        \n",
    "        # tot_syst的y值保持与原tot_syst一致（若存在）\n",
    "        if x_key in tot_x_map:\n",
    "            tot_y = tot_x_map[x_key][1]\n",
    "        else:\n",
    "            tot_y = 0.0\n",
    "        \n",
    "        # x误差：取reso_syst的x误差（或取平均值，根据需求调整）\n",
    "        tot_x_err_low = reso_xl\n",
    "        tot_x_err_high = reso_xh\n",
    "        \n",
    "        # 设置新tot_syst的数据点（非对称误差）\n",
    "        new_tot_graph.SetPoint(idx, x, tot_y)\n",
    "        new_tot_graph.SetPointError(\n",
    "            idx,\n",
    "            tot_x_err_low,   # x下误差\n",
    "            tot_x_err_high,  # x上误差\n",
    "            tot_err_low,     # y下误差（非对称）\n",
    "            tot_err_high     # y上误差（非对称）\n",
    "        )\n",
    "        \n",
    "        print(f\"  x={x:.1f}: \")\n",
    "        print(f\"    fit误差(下/上)={fit_yl:.6f}/{fit_yh:.6f}\")\n",
    "        print(f\"    reso误差(下/上)={reso_yl:.6f}/{reso_yh:.6f}\")\n",
    "        print(f\"    fd误差(下/上)={fd_yl:.6f}/{fd_yh:.6f}\")\n",
    "        print(f\"    → tot误差(下/上)={tot_err_low:.6f}/{tot_err_high:.6f}\")\n",
    "    \n",
    "    # 6. 保存修改后的数据到输出文件\n",
    "    try:\n",
    "        out_file = ROOT.TFile.Open(output_file_path, \"RECREATE\")\n",
    "        if not out_file or out_file.IsZombie():\n",
    "            raise RuntimeError(f\"无法创建输出文件: {output_file_path}\")\n",
    "        print(f\"\\n成功创建输出文件: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"创建输出文件失败: {e}\")\n",
    "        in_file.Close()\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 写入所有对象（保留原对象，替换修改后的reso_syst和tot_syst）\n",
    "    out_file.cd()\n",
    "    # 写入修改后的reso_syst\n",
    "    new_reso_graph.Write()\n",
    "    # 写入重新计算的tot_syst（非对称误差）\n",
    "    new_tot_graph.Write()\n",
    "    # 写入其他未修改的对象\n",
    "    obj_dict[\"fit_syst\"].Write()\n",
    "    obj_dict[\"fd_syst\"].Write()\n",
    "    # 如果有gvn_prompt_stat也一并写入\n",
    "    gvn_stat = in_file.Get(\"gvn_prompt_stat\")\n",
    "    if gvn_stat and isinstance(gvn_stat, ROOT.TGraphAsymmErrors):\n",
    "        gvn_stat.Write()\n",
    "    \n",
    "    # 7. 关闭文件\n",
    "    in_file.Close()\n",
    "    out_file.Close()\n",
    "    \n",
    "    print(f\"\\n处理完成！输出文件: {output_file_path}\")\n",
    "    print(\"修改内容：\")\n",
    "    print(\"  1. reso_syst: 所有点y误差设为y值的0.2%（对称）\")\n",
    "    print(\"  2. tot_syst: 重新计算非对称误差：\")\n",
    "    print(\"     - 下误差 = √(fit_err_low² + reso_err_low² + fd_err_low²)\")\n",
    "    print(\"     - 上误差 = √(fit_err_high² + reso_err_high² + fd_err_high²)\")\n",
    "\n",
    "def main():\n",
    "    # if len(sys.argv) != 3:\n",
    "        # print(\"用法: python adjust_syst.py <输入文件路径> <输出文件路径>\")\n",
    "        # print(\"示例: python adjust_syst.py merged.root f1.root\")\n",
    "        # sys.exit(1)\n",
    "    \n",
    "    input_path = '/home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst.root'\n",
    "    output_path = '/home/xxf/cernbox/Lc/final-fig-paper/paper-fig/input-data/lc-d0-data/merged-lc-promptvn_withsyst_r2-0.2%.root'\n",
    "    adjust_reso_syst_and_recalc_tot(input_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
